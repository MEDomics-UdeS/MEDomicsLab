"""
This program allows the display of 3D scanner and extract its features for different workflows from a JSON file generated by "drawflow_extraction.js".
Uses the "MEDimage" library to filter volumes and extract features according to IBSI: https://github.com/MahdiAll99/MEDimage
Uses the "Plotly" library for 3D volume visualization: https://plotly.com/python/visualizing-mri-volume-slices/

@Author: Corentin GAUTHIER
@email corentin.gauthier@yahoo.com
@github https://github.com/Yslachy
@Version: 0.1
@Date: 09/09/2022
"""
import copy
import json
import os
import pickle
import pprint
import shutil
import sys
from copy import deepcopy
from pathlib import Path

import numpy as np
import pandas as pd
from flask import Blueprint, Response, jsonify, request

MODULE_DIR = str(Path(os.path.dirname(os.path.abspath(__file__))).parent / 'submodules' / 'MEDimage')
sys.path.append(MODULE_DIR)

SUBMODULE_DIR = str(Path(os.path.dirname(os.path.abspath(__file__))).parent.parent)
sys.path.append(SUBMODULE_DIR)

pp = pprint.PrettyPrinter(indent=4, compact=True, width=40, sort_dicts=False)  # allow pretty print of datatypes in console

import ray
import submodules.MEDimage.MEDimage as MEDimage
import utils

# Global variables
cwd = os.getcwd()
isFrontSlash = cwd.find("/")
current_dir = os.path.dirname(os.path.abspath(__file__))
pipelines_json_path = os.path.join(current_dir, "MEDimageApp/settings", "accessible_pipelines.json")
ACCESSIBLE_PIPELINES = json.load(open(pipelines_json_path))
UPLOAD_FOLDER = os.path.join(current_dir, 'MEDimageApp/tmp')
JSON_SETTINGS_PATH = os.path.join(current_dir, 'MEDimageApp/settings/settings_frame.json')

if isFrontSlash == -1:
    UPLOAD_FOLDER = UPLOAD_FOLDER.replace("/", "\\")
    JSON_SETTINGS_PATH = JSON_SETTINGS_PATH.replace("/", "\\")

MED_IMG_OBJ = {}
RUNS = {}
NB_RUNS = 0
df = {}

# Creation of flask blueprint for extraction tab of MEDomicsLab
app_extraction_MEDimage = Blueprint('app_extraction_MEDimage', __name__, static_folder='static', template_folder='templates')


def generateAllPipelines(id: str, node_content, pip, json_scene, pips):
    # -------------------------------------------------- NODE ADD ---------------------------------------------------
    pip.append(id)  # Current node added to pip

    # Specific cases with processing submodule jumps
    if (node_content["name"] == "processing"):
        id_next_node = str(
            int(node_content["id"] + 1))  # Retrieve id of the input_processing node (present in submodule)
        pip.append(id_next_node)  # add second processing into pip
        node_content = utils.get_node_content(id_next_node, json_scene)  # node content updated

    if (node_content["name"] == "output_processing"):
        id_next_node = str(
            node_content["data"]["parent_node"])  # Retrieve id of parent processing node of out_processing node
        pip.append(id_next_node)
        node_content = utils.get_node_content(id_next_node, json_scene)  # node content updated

    # ---------------------------------------------- NEXT NODES COMPUTE ----------------------------------------------
    # NO OUPUT CONNECTION
    if not "output_1" in node_content["outputs"]:  # if no ouput connection
        pips.append(pip)
        return pip

    # ONE OUPUT CONNECTION
    elif len(node_content["outputs"]["output_1"]["connections"]) == 1:
        out_node_id = node_content["outputs"]["output_1"]["connections"][0]["node"]
        out_node_content = utils.get_node_content(out_node_id, json_scene)
        pip = generateAllPipelines(out_node_id, out_node_content, pip, json_scene, pips)

    # MORE ONE OUPUT CONNECTION
    else:
        connections = node_content["outputs"]["output_1"][
            "connections"]  # output connections of last node added to pip
        tab_pip = []
        buff = deepcopy(pip)

        for counter, connection in enumerate(connections):
            tab_pip.append(deepcopy(buff))  # duplicate current pip from connections number
            out_node_id = connection["node"]  # Retrieve output connection of current node
            out_node_content = utils.get_node_content(out_node_id,
                                                      json_scene)  # Retrieve content of node connected of the current node output
            tab_pip[counter] = generateAllPipelines(out_node_id, out_node_content, tab_pip[counter], json_scene, pips)
            pip = tab_pip[counter]

    return pip


def generatePipelinesFromNode(id: str, node_content, pip, json_scene, pips):
    # -------------------------------------------------- NODE ADD ---------------------------------------------------
    pip.append(id)  # Current node added to pip
    print("current pip", pip)

    # Specific cases with processing submodule jumps
    if (node_content["name"] == "input_processing"):
        id_next_node = str(
            int(node_content["id"] - 1))  # Retrieve id of the input_processing node (present in submodule)
        pip.append(id_next_node)  # add second processing into pip
        node_content = utils.get_node_content(id_next_node, json_scene)  # node content updated

    # ---------------------------------------------- NEXT NODES COMPUTE ----------------------------------------------
    # NO INPUT CONNECTION (input node reached)
    if not "input_1" in node_content["inputs"]:  # if no ouput connection
        pip.reverse()
        pips.append(pip)
        return pip

    # ONE INPUT CONNECTION
    elif len(node_content["inputs"]["input_1"]["connections"]) == 1:
        in_node_id = node_content["inputs"]["input_1"]["connections"][0]["node"]
        in_node_content = utils.get_node_content(in_node_id, json_scene)
        pip = generatePipelinesFromNode(in_node_id, in_node_content, pip, json_scene, pips)

    # MORE ONE INPUT CONNECTION
    else:
        print("MULTI input connections : ", len(node_content["inputs"]["input_1"]["connections"]))
        connections = node_content["inputs"]["input_1"]["connections"]  # input connections of last node added to pip
        tab_pip = []
        buff = deepcopy(pip)

        for counter, connection in enumerate(connections):
            tab_pip.append(deepcopy(buff))  # duplicate current pip from connections number
            in_node_id = connection["node"]  # Retrieve input connection of current node
            in_node_content = utils.get_node_content(in_node_id,
                                                     json_scene)  # Retrieve content of node connected of the current node input
            tab_pip[counter] = generatePipelinesFromNode(in_node_id, in_node_content, tab_pip[counter], json_scene,
                                                         pips)
            pip = tab_pip[counter]

    return pip


def formatFeatures(dict):
    for key, value in dict.items():
        if (type(value) is list):
            dict[key] = value
        else:
            dict[key] = np.float64(value)

    return dict


def updatePipSettings(json_scene, pip, im_params, scan_type):
    print("\n*************** UPDATE OF SETTINGS *******************")
    if scan_type == "PTscan":
        scan_type = "imParamPET"
    else:
        scan_type = "imParam" + scan_type[:-4]

    for node in pip:
        content = utils.get_node_content(node, json_scene)

        # FILTER / FILTER_PROCESSING
        if (content["name"] == "filter") or (content["name"] == "filter_processing"):
            im_params["imParamFilter"] = content["data"]
            print("\nParam updated : ", content["name"])
            # pp.pprint(im_params["imParamFilter"])

        # INTERPOLATION
        elif (content["name"] == "interpolation"):
            im_params[scan_type]["interp"] = content["data"]
            print("\nParam updated : ", content["name"])
            pp.pprint(im_params[scan_type]["interp"])

        # RE-SEGMENTATION
        elif (content["name"] == "re_segmentation"):
            im_params[scan_type]["reSeg"] = content["data"]
            print("\nParam updated : ", content["name"])
            pp.pprint(im_params[scan_type]["reSeg"])

        # DISCRETIZATION
        elif (content["name"] == "discretization"):
            im_params[scan_type]["discretisation"] = content["data"]
            print("\nParam updated : ", content["name"])
            pp.pprint(im_params[scan_type]["discretisation"])

    return im_params


def updateNodeInfos(type, settings, output):
    obj = {}
    obj["type"] = type
    obj["settings"] = settings
    obj["output"] = output
    return obj


def getLastNodeOuputEnableFromPip(pip, output_name, nodes_to_parse):
    print("\nOutput research : ", output_name)
    found = False
    i = 1

    while (i <= len(list(pip))):  # Loop stop if current node parsed is the fisrt of the pip
        last_node_found = list(pip)[-i]  # return node's id

        if (pip[last_node_found]["type"] not in nodes_to_parse):  # Current parse node not in the list.
            print("[Try", i, "] Node out of node's list to parse\n \
                    - ID :", last_node_found, "\n \
                    - Node : ", pip[last_node_found]["type"], "\n \
                    - To parse : ", (pip[last_node_found]["type"] in nodes_to_parse))
            i += 1
            
        # NOTE : Ajouté isscalar pour une erreur après la discretization!
        elif np.isscalar(pip[last_node_found]["output"][output_name]):
        # If the element is a scalar (single value or string)
            if pip[last_node_found]["output"][output_name] == "empty":
                print("[Try", i, "] ", output_name, "empty detected \n \
                    - ID :", last_node_found, "\n \
                    - Node : ", pip[last_node_found]["type"], "\n \
                    - Output value : ", pip[last_node_found]["output"][output_name])
                i += 1

        else:  # Ouput found
            found = True
            # last_node_found = list(pip)[-i]  #update with previous node into pip
            last_output_found = deepcopy(pip[last_node_found]["output"][output_name])
            print("[Try", i, "] SUCCESS ! Last ", output_name, " found : \n \
                    - node : ", pip[last_node_found]["type"], "\n \
                    - mem address : ", hex(id(pip[last_node_found]["output"][output_name])), "\n")
            return last_output_found

    if not found: print("Last output not updated")


def getFeaturesList(content, json_scene):
    if (content["name"] == "extraction"):
        features_list = []
        key = "extraction-" + str(content["id"])

        for node_id in json_scene['drawflow'][key]["data"]:  # We scan all node of each modulef in scene
            features_list.append(node_id)

        return features_list

    else:
        print("Node different to extraction not allowed")


def minimumNodeRequired(pip, node_list):
    found = False
    for node in pip:
        if pip[node]["type"] in node_list:
            found = True

    return found


def execute_pips(pips, json_scene):
    # Init RUNS dict for store instances and logs (xxx_obj)
    global NB_RUNS
    NB_RUNS += 1
    pips_obj = {}

    # Init results dict for result response (xxx_res)
    pips_res = {}
    scan_res = {}
    filename_loaded = ""

    # ------------------------------------------ PIP EXECUTION ------------------------------------------
    for pip in pips:

        print("\n\n!!!!!!!!!!!!!!!!!! New pipeline execution !!!!!!!!!!!!!!!!!! \n --> Pip : ", pip)

        # Loading default settings from MEDimageApp json file as im_params
        im_params = MEDimage.utils.json_utils.load_json(JSON_SETTINGS_PATH)

        # Init object and variables for new pipeline
        pip_obj = {}
        pip_name_obj = ""
        pip_res = {}
        pip_name_res = "pip"
        features_res = {}
        settings_res = {}

        # CODE FRAGMENT TO INCLUDE TEXTURE FEATURES
        flag_texture = False
        features_list = []
        # If the pipeline has an extraction node, it must be the last node
        # Check if the last node is an extraction node
        if pip[-1:]:
            last_node_content = utils.get_node_content(pip[-1], json_scene)
            if last_node_content["name"] == "extraction":
                all_texture_features = ["glcm", "gldzm", "glrlm", "glszm", "ngldm", "ngtdm"]
                # Get IDs of nodes contained into feature node
                features_id = getFeaturesList(last_node_content, json_scene)
                for id in features_id:
                    feature_content = utils.get_node_content(id, json_scene)
                    features_list.append(feature_content["name"])
                    if feature_content["name"] in all_texture_features:
                        flag_texture = True

        # Variables to keep segmentation return matrices if there is a texture feature to extract
        vol_obj_init_texture = None
        roi_obj_init_texture = None

        # ------------------------------------------ NODE EXECUTION ------------------------------------------
        for node in pip:
            content = utils.get_node_content(node, json_scene)
            print("\n\n\n///////////////// CURRENT NODE :", content["name"], "-", node, " /////////////////")

            # Update RUNS dict for store instances and logs (xxx_obj)
            update_pip = False
            pip_name_obj += node
            id_obj = {}
            output_obj = {}
            id_obj["type"] = content["name"]
            id_obj["settings"] = content["data"]

            # Update results dict for result response (xxx_res)
            pip_name_res += "/" + node
            nodes_needing_last_output = ["filter", "interpolation", "re_segmentation", "roi_extraction",
                                         "filter_processing", "discretization", "extraction"]

            # ------------------------------ GET LAST VOL and ROI computed ------------------------------------------
            if (content["name"] in nodes_needing_last_output):
                last_vol_compute = getLastNodeOuputEnableFromPip(pip_obj, "vol",
                                                                 ["segmentation", "filter", "interpolation",
                                                                  "re_segmentation", "filter_processing",
                                                                  "roi_extraction", "discretization"]
                                                                 )
                last_roi_compute = getLastNodeOuputEnableFromPip(pip_obj, "roi",
                                                                 ["segmentation", "filter", "interpolation",
                                                                  "re_segmentation", "filter_processing",
                                                                  "roi_extraction", "discretization"]
                                                                 )

            # ------------------------------------------ HOME ------------------------------------------
            # INPUT
            if (content["name"] == "input"):
                print("\n********INPUT execution********")
                print("filename_loaded : ", filename_loaded)
                print("content data : ", content["data"]["filepath"])

                # If new input computed
                if (filename_loaded != content["data"]["filepath"]):
                    print("scan res init")
                    scan_res = {}
                    filename_loaded = content["data"]["filepath"]

                MEDimg = MED_IMG_OBJ[filename_loaded]
                print("---> Instance from \"", filename_loaded, "\" file loaded.")

                scan_type = MEDimg.type
                im_params = updatePipSettings(json_scene, pip, im_params, scan_type)
                print("---> Default params updatted with pipeline settings.")
                MEDimage.MEDscan.init_params(MEDimg, im_params)
                print("---> New params loaded.")

                # Update output infos for RUNS
                update_pip = True
                output_obj["MEDimg"] = MEDimg
                id_obj["output"] = output_obj
                print(" --> outputs updated.")

            # SEGMENTATION
            elif (content["name"] == "segmentation"):

                # Get ROI (region of interest)
                print("\n--> Extraction of ROI mask:")
                print("ROI_NAME apply : ", content["data"]["rois_data"])

                vol_obj_init, roi_obj_init = MEDimage.processing.get_roi_from_indexes(
                    MEDimg,
                    name_roi=content["data"]["rois_data"],
                    # retrieve name_roi from segmentation rois_data. pip[0] match the input id of current pip.
                    box_string="full"
                )
                print(" --> ", content["name"], " executed.")

                # ADDED CODE FRAGMENT FOR TEXTURE FEATURES
                # If there are some texture features to compute later, keep initial version of vol_obj_init
                # and roi_obj_init
                if flag_texture:
                    vol_obj_init_texture = copy.deepcopy(vol_obj_init)
                    roi_obj_init_texture = copy.deepcopy(roi_obj_init)

                # Update output infos
                update_pip = True
                output_obj["vol"] = vol_obj_init
                output_obj["roi"] = roi_obj_init
                id_obj["output"] = output_obj
                print(" --> outputs updated.")
                # Update settings infos pour json response
                settings_res[content["name"]] = content["data"]

            # FILTER
            elif (content["name"] == "filter"):
                MEDimg.params.filter.filter_type = content["data"][
                    "filter_type"]  # Added to get the right filter type before apply_filter function
                vol_obj_filter = MEDimage.filters.apply_filter(MEDimg, last_vol_compute)  # vol_obj_init
                print(" --> ", content["name"], " executed.")

                # Update output infos
                update_pip = True
                output_obj["vol"] = vol_obj_filter
                output_obj["roi"] = "empty"
                id_obj["output"] = output_obj
                print(" --> outputs updated.")
                # Update settings infos pour json response
                settings_res[content["name"]] = content["data"]

            # ------------------------------------------PROCESSING------------------------------------------
            # INTERPOLATION
            elif (content["name"] == "interpolation"):

                # Intensity Mask
                vol_obj = MEDimage.processing.interp_volume(
                    vol_obj_s=last_vol_compute,  # vol_obj_init,
                    medscan=MEDimg,
                    vox_dim=MEDimg.params.process.scale_non_text,
                    interp_met=MEDimg.params.process.vol_interp,
                    round_val=MEDimg.params.process.gl_round,
                    image_type='image',
                    roi_obj_s=last_roi_compute,  # roi_obj_init
                    box_string="full"
                )
                # Morphological Mask
                roi_obj_morph = MEDimage.processing.interp_volume(
                    vol_obj_s=last_roi_compute,  # roi_obj_init,
                    medscan=MEDimg,
                    vox_dim=MEDimg.params.process.scale_non_text,
                    interp_met=MEDimg.params.process.roi_interp,
                    round_val=MEDimg.params.process.roi_pv,
                    image_type='roi',
                    roi_obj_s=last_roi_compute,  # roi_obj_init
                    box_string="full"
                )
                print(" --> ", content["name"], " executed.")

                # Update output infos
                update_pip = True
                output_obj["vol"] = vol_obj
                output_obj["roi"] = roi_obj_morph
                output_obj["roi_morph"] = roi_obj_morph
                id_obj["output"] = output_obj
                print(" --> outputs updated.")
                # Update settings infos pour json response
                settings_res[content["name"]] = content["data"]

            # RE-SEGMENTATION
            elif (content["name"] == "re_segmentation"):

                # Intensity mask range re-segmentation
                roi_obj_int = deepcopy(last_roi_compute)  # roi_obj_morph
                roi_obj_int.data = MEDimage.processing.range_re_seg(
                    vol=last_vol_compute.data,  # vol_obj
                    roi=roi_obj_int.data,
                    im_range=MEDimg.params.process.im_range
                )

                # Intensity mask outlier re-segmentation
                roi_obj_int.data = np.logical_and(
                    MEDimage.processing.outlier_re_seg(
                        vol=last_vol_compute.data,  # vol_obj
                        roi=roi_obj_int.data,
                        outliers=MEDimg.params.process.outliers
                    ),
                    roi_obj_int.data
                ).astype(int)
                print(" --> ", content["name"], " executed.")

                # Update output infos
                update_pip = True
                output_obj["vol"] = "empty"
                output_obj["roi"] = roi_obj_int
                id_obj["output"] = output_obj
                print(" --> outputs updated.")
                # Update settings infos pour json response
                settings_res[content["name"]] = content["data"]

            # ROI_EXTRACTION
            elif (content["name"] == "roi_extraction"):

                # ROI Extraction :
                vol_int_re = MEDimage.processing.roi_extract(
                    vol=last_vol_compute.data,  # vol_obj
                    roi=last_roi_compute.data  # roi_obj_int
                )
                print(" -->", content["name"], " executed.")

                # Update output infos
                update_pip = True
                output_obj["vol"] = vol_int_re
                output_obj["roi"] = "empty"
                id_obj["output"] = output_obj
                print(" --> outputs updated.")

            # DISCRETIZATION
            elif (content["name"] == "discretization"):

                # Intensity histogram equalization of the imaging volume
                if MEDimg.params.process.ivh and 'type' in MEDimg.params.process.ivh and 'val' in MEDimg.params.process.ivh:
                    if MEDimg.params.process.ivh['type'] and MEDimg.params.process.ivh['val']:
                        vol_quant_re, wd = MEDimage.processing.discretize(
                            vol_re=last_vol_compute,  # vol_int_re
                            discr_type=MEDimg.params.process.ivh['type'],
                            n_q=MEDimg.params.process.ivh['val'],
                            user_set_min_val=MEDimg.params.process.user_set_min_value,
                            ivh=True
                        )
                else:
                    vol_quant_re = last_vol_compute
                    wd = 1

                # Update output infos
                update_pip = True
                output_obj["vol"] = vol_quant_re  # temp : to change after new implementation of discretization node
                output_obj["roi"] = "empty"
                id_obj["output"] = output_obj
                print(" --> outputs updated.")
                # Update settings infos for json response
                settings_res[content["name"]] = content["data"]

            # EXTRACTION
            elif (content["name"] == "extraction"):
                # Preparation of computation :
                MEDimg.init_ntf_calculation(last_vol_compute)  # vol_obj

                # ----------------- CODE FRAGMENT ADDED FOR TEXTURE FEATURES -----------------------------------------
                # THIS IS A PATCH : we prepare texture feature for extraction AS IF all the nodes are placed correctly
                # the pipeline.
                if flag_texture:
                    print("Preparation of texture feature extraction.")

                    # TODO : Verifier si on doit bien mettre zero pour scale_text!
                    # Interpolation
                    # Intensity Mask
                    vol_obj_texture = MEDimage.processing.interp_volume(
                        vol_obj_s=vol_obj_init_texture,
                        vox_dim=MEDimg.params.process.scale_text[0],
                        interp_met=MEDimg.params.process.vol_interp,
                        round_val=MEDimg.params.process.gl_round,
                        image_type='image',
                        roi_obj_s=roi_obj_init_texture,
                        box_string=MEDimg.params.process.box_string
                    )
                    # Morphological Mask
                    roi_obj_morph_texture = MEDimage.processing.interp_volume(
                        vol_obj_s=roi_obj_init_texture,
                        vox_dim=MEDimg.params.process.scale_text[0],
                        interp_met=MEDimg.params.process.roi_interp,
                        round_val=MEDimg.params.process.roi_pv,
                        image_type='roi',
                        roi_obj_s=roi_obj_init_texture,
                        box_string=MEDimg.params.process.box_string
                    )

                    # Re-segmentation
                    # Intensity mask range re-segmentation
                    roi_obj_int_texture = deepcopy(roi_obj_morph_texture)
                    roi_obj_int_texture.data = MEDimage.processing.range_re_seg(
                        vol=vol_obj_texture.data,
                        roi=roi_obj_int_texture.data,
                        im_range=MEDimg.params.process.im_range
                    )
                    # Intensity mask outlier re-segmentation
                    roi_obj_int_texture.data = np.logical_and(
                        MEDimage.processing.outlier_re_seg(
                            vol=vol_obj_texture.data,
                            roi=roi_obj_int_texture.data,
                            outliers=MEDimg.params.process.outliers
                        ),
                        roi_obj_int_texture.data
                    ).astype(int)

                    # Image filtering
                    if MEDimg.params.filter.filter_type:
                        vol_obj_texture = MEDimage.filters.apply_filter(MEDimg, vol_obj_texture)

                    a = 0
                    n = 0
                    s = 0

                    # Preparation of computation :
                    MEDimg.init_tf_calculation(
                        algo=a,
                        gl=n,
                        scale=s)

                    # ROI Extraction :
                    vol_int_re_texture = MEDimage.processing.roi_extract(
                        vol=vol_obj_texture.data,
                        roi=roi_obj_int_texture.data)

                    # Discretisation :
                    vol_quant_re_texture, _texture = MEDimage.processing.discretize(
                        vol_re=vol_int_re_texture,
                        discr_type=MEDimg.params.process.algo[a],
                        n_q=MEDimg.params.process.gray_levels[a][n],
                        user_set_min_val=MEDimg.params.process.user_set_min_value
                    )

                # Get IDs of nodes contained into feature node and extract all features selected in node
                features_id = getFeaturesList(content, json_scene)
                for id in features_id:
                    feature_content = utils.get_node_content(id, json_scene)
                    feature_name = feature_content["name"]
                    # Get list of all features to extract
                    features_to_extract = feature_content["data"]["features"]
                    # Initialize features to put in dictionnary
                    features = None

                    # ---------------------------------- NON TEXTURE FEATURES -----------------------------------------
                    # MORPH
                    if feature_name == "morph":

                        nodes_allowed = ["interpolation", "re_segmentation", "filter_processing"]
                        # TODO: Ajouter test permettant de vérifier la présence de certains node dans pip
                        extraction_allowed = minimumNodeRequired(pip_obj, nodes_allowed)

                        if extraction_allowed:
                            last_feat_vol = getLastNodeOuputEnableFromPip(pip_obj, "vol", nodes_allowed)
                            last_feat_roi = getLastNodeOuputEnableFromPip(pip_obj, "roi", nodes_allowed)
                        else:
                            error = "ERROR on " + feature_content[
                                "name"] + " extraction. Minimum one node required from this list :", nodes_allowed
                            return error

                        # Morphological features extraction
                        try:
                            # Create an empty list to store the keys that match the condition
                            roi_morph = []

                            # Iterate through the outer dictionary items
                            for key, inner_dict in pip_obj.items():
                                if 'type' in inner_dict and inner_dict['type'] == 'interpolation':
                                    # Append the key to the list if the condition is met
                                    roi_morph = inner_dict['output']['roi_morph']
                            
                            
                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = MEDimage.biomarkers.morph.extract_all(
                                    vol=last_feat_vol.data,  # vol_obj.data
                                    mask_int=last_feat_roi.data,  # roi_obj_morph.data,
                                    mask_morph=roi_morph.data,  # roi_obj_morph.data,
                                    res=MEDimg.params.process.scale_non_text,
                                    intensity_type=MEDimg.params.process.intensity_type
                                )

                            else:
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    # TODO : Would a for loop be more efficient than calling exec for each feature?
                                    function_name = "MEDimage.biomarkers.morph." + str(features_to_extract[i])
                                    function_params = "vol=last_feat_vol.data, mask_int=last_feat_roi.data, " \
                                                      "mask_morph=last_feat_roi.data, res=MEDimg.params.process.scale_non_text"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "last_feat_vol": last_feat_vol,
                                                   "last_feat_roi": last_feat_roi, "MEDimg": MEDimg}
                                    exec(function_call, global_vars, local_vars)

                                    feature_name_convention = "F" + feature_name + "_" + str(features_to_extract[i])
                                    features[feature_name_convention] = local_vars.get("result")

                            print("---> morph features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF MORPHOLOGICAL FEATURES {str(e)}"}

                    # LOCAL INTENSITY
                    elif feature_name == "local_intensity":
                        nodes_allowed = ["interpolation", "re_segmentation", "filter_processing"]
                        # TODO: Ajouter test permettant de vérifier la présence de certains node dans pip
                        extraction_allowed = minimumNodeRequired(pip_obj, nodes_allowed)

                        if extraction_allowed:
                            last_feat_vol = getLastNodeOuputEnableFromPip(pip_obj, "vol", nodes_allowed)
                            last_feat_roi = getLastNodeOuputEnableFromPip(pip_obj, "roi", nodes_allowed)
                        else:
                            print("ERROR on " + feature_content[
                                "name"] + " extraction. Minimum one node required from this list :", nodes_allowed)

                        # Local intensity features extraction
                        try:
                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = MEDimage.biomarkers.local_intensity.extract_all(
                                    img_obj=last_feat_vol.data,  # vol_obj
                                    roi_obj=last_feat_roi.data,  # roi_obj_int
                                    res=MEDimg.params.process.scale_non_text,
                                    intensity_type=MEDimg.params.process.intensity_type
                                    # TODO: missing parameter that is automatically set to false
                                )
                            else:
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.local_intensity." + str(features_to_extract[i])
                                    function_params = "img_obj=last_feat_vol.data, roi_obj=last_feat_roi.data, " \
                                                      "res=MEDimg.params.process.scale_non_text "
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "last_feat_vol": last_feat_vol,
                                                   "last_feat_roi": last_feat_roi, "MEDimg": MEDimg}
                                    exec(function_call, global_vars, local_vars)

                                    feature_name_convention = "Floc_" + str(features_to_extract[i])
                                    features[feature_name_convention] = local_vars.get("result")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF LOCAL INTENSITY FEATURES {str(e)}"}

                        print("---> local_intensity features extracted")

                    # STATS
                    elif feature_name == "stats":
                        nodes_allowed = [
                            "roi_extraction"]  # not really useful. ROI EXTRACTION dropped by default in GUI
                        extraction_allowed = minimumNodeRequired(pip_obj, nodes_allowed)

                        if extraction_allowed:
                            last_feat_vol = getLastNodeOuputEnableFromPip(pip_obj, "vol", nodes_allowed)
                        else:
                            print("ERROR on ", feature_content["name"],
                                  " extraction. Minimum one node required from this list :", nodes_allowed)

                        # Statistical features extraction
                        try:
                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = MEDimage.biomarkers.stats.extract_all(
                                    vol=last_feat_vol,  # vol_int_re
                                    intensity_type=MEDimg.params.process.intensity_type
                                )
                            else:
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.stats." + str(features_to_extract[i])
                                    function_params = "vol=last_feat_vol"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "last_feat_vol": last_feat_vol}
                                    exec(function_call, global_vars, local_vars)

                                    feature_name_convention = "Fstat_" + str(features_to_extract[i])
                                    features[feature_name_convention] = local_vars.get("result")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF STATISTICAL FEATURES {str(e)}"}

                        print("---> stats features extracted")

                    # IH
                    elif feature_name == "intensity_histogram":
                        nodes_allowed = ["roi_extraction", "discretization"]
                        extraction_allowed = minimumNodeRequired(pip_obj, nodes_allowed)
                        discretization = minimumNodeRequired(pip_obj,
                                                             ["discretization"])  # if dicretization in current pip

                        if discretization:
                            last_vol_compute = getLastNodeOuputEnableFromPip(pip_obj, "vol", ["roi_extraction"])
                            # Intensity histogram equalization of the imaging volume (DISCRETIZATION)
                            last_feat_vol, _ = MEDimage.processing.discretize(
                                vol_re=last_vol_compute,  # vol_int_re
                                discr_type=MEDimg.params.process.ih['type'],
                                n_q=MEDimg.params.process.ih['val'],
                                user_set_min_val=MEDimg.params.process.user_set_min_value
                            )
                            print("---> discretization executed.")

                        elif extraction_allowed:
                            last_feat_vol = getLastNodeOuputEnableFromPip(pip_obj, "vol", nodes_allowed)

                        else:
                            print("ERROR on ", feature_content["name"],
                                  " extraction. Minimum one node required from this list :", nodes_allowed)

                        # Intensity histogram features extraction
                        try:
                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = MEDimage.biomarkers.intensity_histogram.extract_all(vol=last_feat_vol)
                            else:
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.intensity_histogram." + str(
                                        features_to_extract[i])
                                    function_params = "vol=last_feat_vol"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "last_feat_vol": last_feat_vol}
                                    exec(function_call, global_vars, local_vars)

                                    feature_name_convention = "Fih_" + str(features_to_extract[i])
                                    features[feature_name_convention] = local_vars.get("result")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF INTENSITY HISTOGRAM FEATURES {str(e)}"}

                        print("---> intensity_histogram features extracted")

                    # IVH
                    elif feature_name == "int_vol_hist":
                        nodes_allowed = ["roi_extraction", "discretization"]
                        extraction_allowed = minimumNodeRequired(pip_obj, nodes_allowed)
                        discretization = minimumNodeRequired(pip_obj,
                                                             ["discretization"])  # if dicretization in current pip

                        if discretization:
                            last_vol_compute = getLastNodeOuputEnableFromPip(pip_obj, "vol", ["roi_extraction"])

                            # Intensity histogram equalization of the imaging volume
                            if MEDimg.params.process.ivh and 'type' in MEDimg.params.process.ivh and 'val' in MEDimg.params.process.ivh:
                                if MEDimg.params.process.ivh['type'] and MEDimg.params.process.ivh['val']:
                                    last_feat_vol, wd = MEDimage.processing.discretize(
                                        vol_re=last_vol_compute,  # vol_int_re
                                        discr_type=MEDimg.params.process.ivh['type'],
                                        n_q=MEDimg.params.process.ivh['val'],
                                        user_set_min_val=MEDimg.params.process.user_set_min_value,
                                        ivh=True
                                    )
                            print("---> discretization executed.")

                        elif extraction_allowed:
                            last_feat_vol = getLastNodeOuputEnableFromPip(pip_obj, "vol", nodes_allowed)
                            wd = 1

                        else:
                            print("ERROR on ", feature_content["name"],
                                  " extraction. Minimum one node required from this list :", nodes_allowed)

                        # Intensity volume histogram features extraction
                        try:
                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = MEDimage.biomarkers.int_vol_hist.extract_all(
                                    medscan=MEDimg,
                                    vol=last_feat_vol,  # vol_quant_re
                                    vol_int_re=vol_int_re,
                                    wd=wd  # TODO: Missing user_set_range argument?
                                )
                            else:
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.int_vol_hist." + str(features_to_extract[i])
                                    function_params = "medscan=MEDimg, vol=last_feat_vol, vol_int_re=vol_int_re, wd=wd"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "last_feat_vol": last_feat_vol,
                                                   "vol_int_re": vol_int_re, "MEDimg": MEDimg, "wd": wd}
                                    exec(function_call, global_vars, local_vars)

                                    feature_name_convention = "F" + feature_name + "_" + str(features_to_extract[i])
                                    features[feature_name_convention] = local_vars.get("result")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF INTENSITY VOLUME HISTOGRAM FEATURES {str(e)}"}

                        print("---> ivh features extracted")

                    # ------------------------------------- TEXTURE FEATURES ------------------------------------------
                    # GLCM
                    elif feature_name == "glcm":
                        try:
                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = MEDimage.biomarkers.glcm.extract_all(
                                    vol=vol_quant_re_texture,
                                    dist_correction=MEDimg.params.radiomics.glcm.dist_correction,
                                    merge_method=MEDimg.params.radiomics.glcm.merge_method)
                            else:
                                # Extracts co-occurrence matrices from the intensity roi mask prior to features
                                # extraction (note : this is done in the extract_all function if all features were to
                                # be extracted).
                                matrices_dict = MEDimage.biomarkers.glcm.get_glcm_matrices(vol_quant_re_texture,
                                                                                       merge_method=MEDimg.params.radiomics.glcm.merge_method,
                                                                                       dist_weight_norm=MEDimg.params.radiomics.glcm.dist_correction)

                                # If not all features need to be extracted, use the name of each feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.glcm." + str(features_to_extract[i])
                                    function_params = "matrices_dict"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "matrices_dict": matrices_dict}
                                    exec(function_call, global_vars, local_vars)

                                    feature_name_convention = "Fcm_" + str(features_to_extract[i])
                                    features[feature_name_convention] = local_vars.get("result")

                            print("---> glcm features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF GLCM FEATURES {str(e)}"}

                    # GLRLM
                    elif feature_name == "glrlm":
                        try:
                            # TODO : temporary code used to replace single feature extraction for user
                            all_features = MEDimage.biomarkers.glrlm.extract_all(
                                vol=vol_quant_re_texture,
                                dist_correction=MEDimg.params.radiomics.glrlm.dist_correction,
                                merge_method=MEDimg.params.radiomics.glrlm.merge_method)

                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = all_features
                            else:
                                features = {}
                                for i in range(len(features_to_extract)):
                                    feature_name_convention = "Frlm_" + str(features_to_extract[i])
                                    features[feature_name_convention] = all_features[feature_name_convention]

                                """ NOTE : Code to use in prevision of future MEDimage update allowing extraction of single features
                                matrices_dict = MEDimage.biomarkers.glrlm.get_glrlm_matrices(
                                    vol=vol_quant_re_texture,
                                    dist_correction=MEDimg.params.radiomics.glrlm.dist_correction,
                                    merge_method=MEDimg.params.radiomics.glrlm.merge_method)

                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.glrlm." + str(features_to_extract[i])
                                    function_params = "matrices_dict"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "matrices_dict": matrices_dict}
                                    exec(function_call, global_vars, local_vars)
                                    features[str(features_to_extract[i])] = local_vars.get("result")
                                """

                            print("---> glrlm features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF GLRLM FEATURES {str(e)}"}

                    # GLSZM
                    elif feature_name == "glszm":
                        try:
                            # TODO : temporary code used to replace single feature extraction for user
                            all_features = MEDimage.biomarkers.glszm.extract_all(
                                vol=vol_quant_re_texture)

                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = all_features
                            else:
                                features = {}
                                for i in range(len(features_to_extract)):
                                    feature_name_convention = "Fszm_" + str(features_to_extract[i])
                                    features[feature_name_convention] = all_features[feature_name_convention]

                                """ NOTE : Code to use in prevision of future MEDimage update allowing extraction of single features
                                matrices_dict = MEDimage.biomarkers.glszm.get_glszm_matrices(
                                    vol=vol_quant_re_texture)
                                
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.glszm." + str(features_to_extract[i])
                                    function_params = "matrices_dict"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "matrices_dict": matrices_dict}
                                    exec(function_call, global_vars, local_vars)
                                    features[str(features_to_extract[i])] = local_vars.get("result")
                                """

                            print("---> glszm features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF GLSZM FEATURES {str(e)}"}

                    # GLDZM
                    elif feature_name == "gldzm":
                        try:
                            # TODO : temporary code used to replace single feature extraction for user
                            all_features = MEDimage.biomarkers.gldzm.extract_all(
                                    vol_int=vol_quant_re_texture,
                                    mask_morph=roi_obj_morph_texture.data)

                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = all_features
                            else:
                                features = {}
                                for i in range(len(features_to_extract)):
                                    feature_name_convention = "Fdzm_" + str(features_to_extract[i])
                                    features[feature_name_convention] = all_features[feature_name_convention]

                                """ NOTE : Code to use in prevision of future MEDimage update allowing extraction of single features
                                matrices_dict = MEDimage.biomarkers.gldzm.get_gldzm_matrices(
                                    vol_int=vol_quant_re_texture,
                                    mask_morph=roi_obj_morph_texture.data)
                                
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.gldzm." + str(features_to_extract[i])
                                    function_params = "matrices_dict"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "matrices_dict": matrices_dict}
                                    exec(function_call, global_vars, local_vars)
                                    features[str(features_to_extract[i])] = local_vars.get("result")
                                """

                            print("---> gldzm features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF GLDZM FEATURES {str(e)}"}

                    # NGTDM
                    elif feature_name == "ngtdm":
                        try:
                            # TODO : temporary code used to replace single feature extraction for user
                            all_features = MEDimage.biomarkers.ngtdm.extract_all(
                                    vol=vol_quant_re_texture,
                                    dist_correction=MEDimg.params.radiomics.ngtdm.dist_correction)

                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = all_features
                            else:
                                features = {}
                                for i in range(len(features_to_extract)):
                                    feature_name_convention = "Fngt_" + str(features_to_extract[i])
                                    features[feature_name_convention] = all_features[feature_name_convention]

                                """ NOTE : Code to use in prevision of future MEDimage update allowing extraction of single features
                                matrices_dict = MEDimage.biomarkers.ngtdm.get_ngtdm_matrices(
                                    vol=vol_quant_re_texture,
                                    dist_correction=MEDimg.params.radiomics.ngtdm.dist_correction)
                                
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.ngtdm." + str(features_to_extract[i])
                                    function_params = "matrices_dict"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "matrices_dict": matrices_dict}
                                    exec(function_call, global_vars, local_vars)
                                    features[str(features_to_extract[i])] = local_vars.get("result")
                                """

                            print("---> ngtdm features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF NGTDM FEATURES {str(e)}"}

                    # NGLDM
                    elif feature_name == "ngldm":
                        try:
                            # TODO : temporary code used to replace single feature extraction for user
                            all_features = MEDimage.biomarkers.ngldm.extract_all(
                                    vol=vol_quant_re_texture)

                            # If all features need to be extracted
                            if features_to_extract[0] == "extract_all":
                                features = all_features
                            else:
                                features = {}
                                for i in range(len(features_to_extract)):
                                    feature_name_convention = "Fngl_" + str(features_to_extract[i])
                                    features[feature_name_convention] = all_features[feature_name_convention]

                                """ NOTE : Code to use in prevision of future MEDimage update allowing extraction of single features
                                matrices_dict = MEDimage.biomarkers.ngldm.get_ngldm_matrices(
                                    vol=vol_quant_re_texture)
                                
                                # If only some features need to be extracted, use the name of the feature to build
                                # extraction code (executed dynamically using exec()).
                                features = {}
                                for i in range(len(features_to_extract)):
                                    function_name = "MEDimage.biomarkers.ngldm." + str(features_to_extract[i])
                                    function_params = "matrices_dict"
                                    function_call = "result = " + function_name + "(" + function_params + ")"
                                    local_vars = {}
                                    global_vars = {"MEDimage": MEDimage, "matrices_dict": matrices_dict}
                                    exec(function_call, global_vars, local_vars)
                                    features[str(features_to_extract[i])] = local_vars.get("result")
                                """

                            print("---> ngldm features extracted")
                        except Exception as e:
                            return {"error": f"PROBLEM WITH COMPUTATION OF NGLDM FEATURES {str(e)}"}

                    # FEATURE NOT FOUND
                    else:
                        print("Feature : ", feature_name, " is not a valid feature name.")

                    # Add feature to dictionnary
                    if features is not None:
                        features = formatFeatures(features)
                        features_res[feature_name] = features  # UP response
                        output_obj[feature_name] = features  # UP runs

                # Update output infos of extraction node
                update_pip = True
                id_obj["output"] = output_obj

            # NODE NOT FOUND
            else:
                print("Node not implemented yet:", content["name"])

                # add relevant nodes
            if (update_pip):
                pip_obj[content["id"]] = id_obj

        # pip features and settings update
        pip_res["features"] = features_res
        pip_res["settings"] = settings_res
        scan_res[pip_name_res] = pip_res

        pips_res[filename_loaded] = scan_res  # pips response update
        pips_obj[pip_name_obj] = pip_obj  # pips object update

    RUNS[NB_RUNS] = pips_obj
    print("\n************ TOTAL RUNS ************")
    pp.pprint(RUNS)

    return pips_res

# Run DataManager
@app_extraction_MEDimage.route('/run/dm', methods=['GET', 'POST'])
def RunDM():
    if request.method == 'POST':
        data = request.get_json()
        keys = list(data.keys())
        data = data[keys[0]]

    # Retrieve data from json request
    if "pathDicoms" in data.keys() and data["pathDicoms"] != "":
        path_to_dicoms = Path(data["pathDicoms"])
    else:
        path_to_dicoms = None
    if "pathNiftis" in data.keys() and data["pathNiftis"] != "":
        path_to_niftis = Path(data["pathNiftis"])
    else:
        path_to_niftis = None
    if "pathSave" in data.keys() and data["pathSave"] != "":
        path_save = Path(data["pathSave"])
    if "pathCSV" in data.keys() and data["pathCSV"] != "":
        path_csv = Path(data["pathCSV"])
    else:
        path_csv = None
    if "save" in data.keys():
        save = data["save"]
    if "nBatch" in data.keys():
        n_batch = data["nBatch"]

    # Check if at least one path to data is given
    if not ("pathDicoms" in data.keys() and data["pathDicoms"] != "") and not (
            "pathNiftis" in data.keys() and data["pathNiftis"] != ""):
        print("No path to data given")
        return Response("No path to data given! At least DICOM or NIFTI path must be given.", status=400)
    
     # Init DataManager instance
    dm = MEDimage.wrangling.DataManager(
        path_to_dicoms=path_to_dicoms,
        path_to_niftis=path_to_niftis,
        path_save=path_save,
        path_csv=path_csv,
        save=save, 
        n_batch=n_batch)

    # Run the DataManager
    if path_to_dicoms is not None and path_to_niftis is None:
        dm.process_all_dicoms()
    elif path_to_dicoms is None and path_to_niftis is not None:
        dm.process_all_niftis()
    else:
        dm.process_all()
    
    # Return success message
    summary = dm.summarize(return_summary=True).to_dict()
    
    # Get the number of rows
    num_rows = len(summary["count"])

    # Create a list of objects in the desired format
    result = []
    for i in range(num_rows):
        obj = {
            "count": summary["count"][i],
            "institution": summary["institution"][i],
            "roi_type": summary["roi_type"][i],
            "scan_type": summary["scan_type"][i],
            "study": summary["study"][i]
        }
        result.append(obj)

    return jsonify(result)

# Run Radiomics pre-checks
@app_extraction_MEDimage.route('/run/dm/prechecks', methods=['GET', 'POST'])
def RunPreChecks():
    if request.method == 'POST':
        data = request.get_json()
        keys = list(data.keys())
        data = data[keys[0]]

    # Retrieve data from json request
    if "pathDicoms" in data.keys() and data["pathDicoms"] != "":
        path_to_dicoms = Path(data["pathDicoms"])
    else:
        path_to_dicoms = None
    if "pathNiftis" in data.keys() and data["pathNiftis"] != "":
        path_to_niftis = Path(data["pathNiftis"])
    else:
        path_to_niftis = None
    if "pathSave" in data.keys() and data["pathSave"] != "":
        path_save = Path(data["pathSave"])
    if "pathCSV" in data.keys() and data["pathCSV"] != "":
        path_csv = Path(data["pathCSV"])
    else:
        path_csv = None
    if "save" in data.keys():
        save = data["save"]
    if "nBatch" in data.keys():
        n_batch = data["nBatch"]
    if "wildcards_dimensions" in data.keys():
        wildcards_dimensions = data["wildcards_dimensions"]
    else:
        wildcards_dimensions = None
    if "wildcards_window" in data.keys():
        wildcards_window = data["wildcards_window"]
    else:
        wildcards_window = None
    
    # Check if wildcards are given
    if not wildcards_dimensions and not wildcards_window:
        return Response("No wildcards given! both wildcard for dimensions and for window must be given.", status=400)
    
    # path save (TODO: find another work-around)
    path_save_checks = Path.cwd() / "renderer/public/images"

    # Init DataManager instance
    dm = MEDimage.wrangling.DataManager(
        path_to_dicoms=path_to_dicoms,
        path_to_niftis=path_to_niftis,
        path_save=path_save,
        path_csv=path_csv,
        path_save_checks=path_save_checks,
        save=save, 
        n_batch=n_batch)

    # Run the DataManager
    dm.pre_radiomics_checks(
        path_data=path_save,
        wildcards_dimensions=wildcards_dimensions, 
        wildcards_window=wildcards_window, 
        path_csv=path_csv,
        save=True)

    # Get pre-checks images
    # Find all png files in path
    list_png = list((path_save_checks / 'checks').glob('*.png'))
    list_titles = [png.name for png in list_png]
    list_png = [str(png) for png in list_png]
    url_list = ['.' + png.split('public')[-1].replace('\\', '/') for png in list_png]
    
    # Return success message
    return jsonify({"url_list": url_list, "list_titles": list_titles, "message": "Pre-checks done successfully."}) 

# Get extraction settings
@app_extraction_MEDimage.route('/get/json', methods=['GET', 'POST'])
def getExtractionParams():
    # Get path
    if request.method == 'POST':
        path_settings = request.get_json()
        keys = list(path_settings.keys())
        path_settings = path_settings[keys[0]]['selectedSettingsFile']
    try:
        settings_dict = json.load(open(path_settings, 'r'))
    except Exception as e:
        return {"error": f"PROBLEM WITH LOADING SETTINGS {str(e)}"}

    return jsonify(settings_dict)

# Save extraction settings
@app_extraction_MEDimage.route('/save/json', methods=['GET', 'POST'])
def saveExtractionParams():
    # Get path
    if request.method == 'POST':
        settings = request.get_json()
        keys = list(settings.keys())
        path_save = settings[keys[0]]['pathSettings']
        settings = settings[keys[0]]['settings']
    try:
        json.dump(settings, open(path_save, 'w'), indent=4)
    except Exception as e:
        return {"error": f"PROBLEM WITH SAVING SETTINGS {str(e)}"}

    return jsonify("Settings saved successfully.")

# Run BatchExtractor
@app_extraction_MEDimage.route('/count/be', methods=['GET', 'POST'])
def RunBECount():
    if request.method == 'POST':
        data = request.get_json()
        keys = list(data.keys())
        data = data[keys[0]]

    # Retrieve data from json request
    if "path_read" in data.keys() and data["path_read"] != "":
        path_read = Path(data["path_read"])
    else:
        return Response("No path to data given!", status=400)
    if "path_csv" in data.keys() and data["path_csv"] != "":
        path_csv = Path(data["path_csv"])
    else:
        return Response("No path to csv given!", status=400)
    if "path_params" in data.keys() and data["path_params"] != "":
        path_params = Path(data["path_params"])
    else:
        return Response("No path to params given!", status=400)
    if "path_save" in data.keys() and data["path_save"] != "":
        path_save = Path(data["path_save"])
    else:
        path_save = None

    # CSV file path process
    if str(path_csv).endswith('.csv'):
        path_csv = path_csv.parent
    
    # Load params
    with open(path_params, 'r') as f:
        params = json.load(f)
    
    # Load csv and count scans
    tabel_roi = pd.read_csv(path_csv / ('roiNames_' + params["roi_type_labels"][0] + '.csv'))
    tabel_roi['under'] = '_'
    tabel_roi['dot'] = '.'
    tabel_roi['npy'] = '.npy'
    name_patients = (pd.Series(
        tabel_roi[['PatientID', 'under', 'under',
                'ImagingScanName',
                'dot',
                'ImagingModality',
                'npy']].fillna('').values.tolist()).str.join('')).tolist()
    
    
    # Count scans in path read
    list_scans = [scan.name for scan in list(path_read.glob('*.npy'))]
    list_scans_unique = [name_patient for name_patient in name_patients if name_patient in list_scans]
    n_scans = len(list_scans_unique)

    if type(params["roi_types"]) is list:
        roi_label = params["roi_types"][0]
    else:
        roi_label = params["roi_types"]
    folder_save_path = path_save / f'features({roi_label})'
    
    return jsonify({"n_scans": n_scans, "folder_save_path": str(folder_save_path)})

# Run BatchExtractor
@app_extraction_MEDimage.route('/run/be', methods=['GET', 'POST'])
def RunBE():
    if request.method == 'POST':
        data = request.get_json()
        keys = list(data.keys())
        data = data[keys[0]]

    # Retrieve data from json request
    if "path_read" in data.keys() and data["path_read"] != "":
        path_read = Path(data["path_read"])
    else:
        path_read = None
    if "path_save" in data.keys() and data["path_save"] != "":
        path_save = Path(data["path_save"])
    if "path_csv" in data.keys() and data["path_csv"] != "":
        path_csv = Path(data["path_csv"])
    else:
        path_csv = None
    if "path_params" in data.keys() and data["path_params"] != "":
        path_params = Path(data["path_params"])
    else:
        path_params = None
    if "n_batch" in data.keys():
        n_batch = data["n_batch"]

    # CSV file path process
    if 'csv' in path_csv.name:
        path_csv = path_csv.parent
    
    # Check if at least one path to data is given
    if not ("path_read" in data.keys() and data["path_read"] != "") and not (
            "path_params" in data.keys() and data["path_params"] != "") and not (
            "path_csv" in data.keys() and data["path_csv"] != ""):
        print("Multiple arguments missing")
        return Response("Path read, settings, csv and save must be given.", status=400)
    
     # Init BatchExtractor instance
    be = MEDimage.biomarkers.BatchExtractor(
        path_read=path_read,
        path_csv=path_csv,
        path_params=path_params,
        path_save=path_save,
        n_batch=n_batch)

    # Run the BatchExtractor
    be.compute_radiomics()
    
    return Response("Successfuly extracted features from batch", status=200)

# Upload file in Input Object node
@app_extraction_MEDimage.route('/upload', methods=['GET', 'POST'])
def getUpload():  # Code selected from  https://flask.palletsprojects.com/en/2.2.x/patterns/fileuploads/
    try:
        up_file_infos = {}
        data = utils.get_json_from_request(request)
        print("received data from topic: /upload:")
        pp.pprint(data)
        print("request:")
        print(request)
        if request.method == 'POST':
            # data = request.get_json()
            ######################################################################################
            # CHECK IF THE REQUEST GAVE A FILE OR A FOLDER
            # IF THE REQUEST IS A FILE, AND THE FILE IS A NPY FILE, TRY OPENING IT AS A MEDIMAGE
            # PICKLE OBJECT.
            # IF THE REQUEST IS A FOLDER, TRY OPENING IT AS A DICOM IMAGE USING MEDIMAGE.
            ######################################################################################

            # check if the post request has the file part
            if 'file' not in data:
                return {"error": {"toast": "No file part"}}

            file = data["file"]
            file_type = data["type"]

            if file_type == "folder":
                # Initialize the DataManager class
                path_to_dicoms = file
                dm = MEDimage.wrangling.DataManager(path_to_dicoms=path_to_dicoms, path_save=UPLOAD_FOLDER, save=True)

                # Process the DICOM scan
                dm.process_all_dicoms()

                # Ray doesnt need to be shutdown in MEDimage but needs to be shutdown here to avoid
                # connection error with the Flask server continues to run
                ray.shutdown()

                # Get the path to the file created by MEDimage
                file = dm.path_to_objects[0]

                # Check if the file is a valid pickle object
            if file and utils.allowed_pickle_object(file):
                # TODO : For the moment the file is copied in the UPLOAD_FOLDER
                # but since the app is a local app, it doesn't need to be copied.
                # filename = secure_filename(file)
                filename = os.path.basename(file)
                file_path = os.path.join(UPLOAD_FOLDER, filename)

                if file_type == "file":
                    shutil.copy2(file, file_path)
                    # file.save(file_path)

                # Load and store MEDimage instance from file loaded
                with open(file_path, 'rb') as f:
                    medscan = pickle.load(f)
                medscan = MEDimage.MEDscan(medscan)
                MED_IMG_OBJ[filename] = medscan

                # Return infos of instance loaded
                ROIS_list = medscan.data.ROI.roi_names
                up_file_infos["name"] = filename
                up_file_infos["rois_list"] = ROIS_list
                return jsonify(up_file_infos)
            else:
                return {"error": {"toast": "The file you tried to upload doesnt have the right format."}}
        else:
            return {"error": {"toast": "The request method is not POST."}}
    except BaseException as e:
        return utils.get_response_from_error(e)



# Run all button to run all drawflow pipelines
@app_extraction_MEDimage.route("/run-all", methods=["GET","POST"])
def runAll():
    try:
        if not bool(MED_IMG_OBJ):
            print("\n No instance of MEDimage object are loaded. Impossible to run any pipeline.")
            # Returns empty dict for the moment. TODO: error message in javascript!
            return {"error": {"toast": "No instance of MEDimage object are loaded. Impossible to run any pipeline."}}


        print("\nThe current loaded instances of MEDimage objects are :", MED_IMG_OBJ)

        json_scene = utils.get_json_from_request(request)
        drawflow_scene = json_scene['drawflow']

        pips = []  # Initialize pipeline list

        for module in drawflow_scene:  # We scan all module in scene
            for node_id in drawflow_scene[module]['data']:  # We scan all node of each module in scene
                node_content = drawflow_scene[module]['data'][node_id]  # Getting node content
                if node_content["name"] == "input":  # If the node name is input, it is the start of a pipeline
                    pip = []
                    pip = generateAllPipelines(str(node_content["id"]), node_content, [], json_scene,
                                               pips)  # This function modifies pips value

        print("\n The pipelines found in the current drawflow scene are : ", pips)
        json_res = execute_pips(pips, json_scene)

        ### TODO: FIX PIPELINES NAMES ###
        # Checking if the pipelines are all IBSI compliant
        executable_pipelines = {}
        # pipeline_generator = utils.gen_dict_extract('pipeline', ACCESSIBLE_PIPELINES)
        # for pip in pips:
        #    if pip not in pipeline_generator:
        #        print("Will not account for pipeline ", pip, " since it is not IBSI compliant.") #TODO : message d'erreur a l'utilisateur
        #    else:
        #        del json_res['pip']

        return json_res  # return pipeline results in the form of a dict
    except BaseException as e:
        return utils.get_response_from_error(e)


# TODO : Verifier si le node peut bien etre execute
@app_extraction_MEDimage.route('/run', methods=['GET', 'POST'])
def run():
    try:
        data = utils.get_json_from_request(request)
        json_scene = data["json_scene"]

        start_id = data["id"]  # id of node where run button was clicked
        print("The id of the node to run is : ", start_id)

        pips = []
        pip = []
        pip = generatePipelinesFromNode(str(start_id), utils.get_node_content(start_id, json_scene), pip, json_scene, pips)

        print("The pipelines found ending with node ", start_id, " are ", pips)
        json_res = execute_pips(pips, json_scene)

        return json_res
    except BaseException as e:
        return utils.get_response_from_error(e)


# TODO : Verifier si fonctionne aussi pour d'autre types que des images IRM. (TEP devrait etre couleur, IRM et CT noir et blanc).
@app_extraction_MEDimage.route('/view', methods=['GET', 'POST'])
def get3DView():
    try:
        data = utils.get_json_from_request(request)
        print("User asked for view of : ", data)

        utils.image_viewer(MED_IMG_OBJ, data, RUNS)
        return Response("OK", status = 200)
    except BaseException as e:
        return utils.get_response_from_error(e)
